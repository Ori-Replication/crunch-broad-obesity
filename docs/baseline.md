### 2. 针对“未知单扰动”（Unseen Single Perturbation）的线性模型
这是该论文中技术含量最高的部分。为了公平竞争，作者设计了一个基于嵌入（Embedding）的线性模型（LM），试图用最少的参数实现预测。

#### A. 模型结构
模型的核心思想是将基因表达矩阵 $Y$ 分解为三个部分的乘积（见论文图2b和公式1）：
$$Y \approx G W P^T + b$$

*   **$G$ (Gene Embeddings)：** 基因的特征向量矩阵。它代表了每个基因在生物学空间中的“位置”。
*   **$P$ (Perturbation Embeddings)：** 扰动的特征向量矩阵。它代表了不同的实验处理（如敲除某个基因）的特征。
*   **$W$ (Weight Matrix)：** 线性权重矩阵。这是模型唯一需要学习的部分，用于描述“扰动特征”如何通过“基因特征”转化为最终的“表达量变化”。
*   **$b$：** 训练数据的行均值，用于中心化。

#### B. 嵌入（Embeddings）的来源
作者展示了线性模型的强大适应性，它可以利用多种方式获取特征向量：
1.  **基于训练集的PCA：** 直接对训练数据进行主成分分析（PCA），取前 $K$ 个主成分作为 $G$。默认 K = 10 ，为可调整的超参数。

#### C. 优化与求解
作者使用了**岭回归（Ridge Regression）**来求解 $W$（见论文公式3）。通过引入一个正则化参数 $\lambda = 0.1$ 来保证数值计算的稳定性。相比于深度学习需要消耗大量GPU资源进行成千上万次的迭代，这个线性模型通过矩阵运算（普通最小二乘法的变体）即可快速得到闭式解。

在论文的“Methods”部分（第6-7页）以及“Single perturbation benchmark setup”章节中，作者详细描述了这个打败深度学习模型的线性模型（Linear Model, LM）。

以下是该模型的详细技术拆解：

### 1. 模型的核心数学公式
该模型试图将基因表达量的变化建模为基因特征向量和扰动特征向量的线性组合：
$$\hat{Y} = GWP^T + b$$

*   **$\hat{Y}$**：预测的基因表达矩阵（基因数 $\times$ 扰动条件数）。
*   **$G$ (Gene Embeddings)**：基因特征矩阵（基因数 $\times K$）。它代表每个“受影响基因”的生物学背景特征。
*   **$P$ (Perturbation Embeddings)**：扰动特征矩阵（扰动条件数 $\times L$）。它代表每个“扰动目标基因”的特征。
*   **$W$**：需要学习的权重矩阵（$K \times L$）。
*   **$b$**：截距向量，通常是训练集中每个基因的平均表达量（Row Means）。

### 2. 矩阵的具体产生方式
这是该模型最有趣的地方，作者展示了如何用极其简单的方法生成这些矩阵：

#### **G 矩阵（基因嵌入）的产生：**
*   作者直接对训练集的基因表达矩阵 $Y_{train}$ 进行 **PCA（主成分分析）**。
*   取 PCA 的前 **$K$ 个主成分** 作为 $G$。
*   **逻辑：** 即使没有复杂的预训练，PCA 也能捕捉到基因之间最主要的共表达关系和生物学模块。

#### **P 矩阵（扰动嵌入）的产生：**
*   对于“单基因扰动”，扰动的是基因 X，那么 $P$ 矩阵中对应这个扰动条件的行，就直接取 **$G$ 矩阵中基因 X 那一行**。
*   **逻辑：** 如果我们要扰动基因 X，那么基因 X 本身的特征（它在细胞调控网中的位置）就是这个扰动最好的表征。

#### **W 矩阵（权重）的求解：**
*   作者没有使用梯度下降或反向传播，而是使用了带有 **岭回归（Ridge Regression）** 惩罚项的“正规方程”（Normal Equations）来直接计算闭式解：
    $$W = (G^T G + \lambda I)^{-1} G^T (Y_{train} - b) P (P^T P + \lambda I)^{-1}$$
*   这种方法计算速度极快，且具有全局最优解。

### 3. 超参数设置
作者选择了非常保守且通用的超参数，没有进行过度的调参（Hyperparameter Tuning）：

*   **$K$ (维度)**：设置为 **10**。这意味着他们只用 10 个特征来代表一个基因。
*   **$\lambda$ (正则化系数)**：设置为 **0.1**。这是为了防止在矩阵求逆时出现数值不稳定，并起到一定的防过拟合作用。
*   **读取基因数 (Read-out Genes)**：基准测试聚焦于表达量最高的 **1,000 个基因**。

### 4. 训练与测试的划分（Train/Test Split）
作者严格遵循了之前深度学习模型（如 GEARS）所使用的划分协议，以确保对比的公平性：

*   **未知单扰动 (Unseen Single Perturbation)**：
    *   **定义：** 测试集中被扰动的基因，在训练集中**从未**被扰动过。
    *   **难度：** 这要求模型必须具备真正的泛化能力，通过理解基因之间的关系来预测从未见过的实验结果。
*   **重复实验：** 所有的分析都运行了多次（单扰动 2 次，双扰动 5 次），使用不同的随机种子进行数据划分，以确保结果不是偶然。
*   **伪批量化 (Pseudobulk)**：在输入线性模型前，作者将单细胞数据按扰动条件进行了聚合（计算平均值），这大大降低了噪声，也是线性模型能够高效运行的关键。

### 5. 实验数据的规模
模型在以下几个经典数据集上进行了测试：
*   **Norman (K562)**：124个双扰动，100个单扰动。
*   **Adamson (K562)**：81个单扰动。
*   **Replogle (K562 & RPE1)**：超过 1000 个单扰动。

### 总结：线性模型的“取胜之道”
作者设计的这个模型本质上是一个**低秩线性回归**。

相比之下，scGPT 等模型试图在极高维的空间中建模非线性关系。然而，论文通过实验证明：在当前的基因扰动数据集规模下，**增加的模型复杂度带来的只有噪声，而没有更多的预测精度**。作者通过将 $K$ 设为 10 这种极端降维的方式，强迫模型只学习最稳健的生物学信号，从而在泛化能力上彻底击败了深层的神经网络。